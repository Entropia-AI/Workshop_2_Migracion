{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook \\# 1: Extracci칩n, transformaci칩n y carga de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias 칰tiles\n",
    "\n",
    "Una vez que se cuenta con el conjunto de datos etiquetado, 칠ste debe ser dividido en tres subconjuntos que llamaremos \"entrenamiento\", \"validaci칩n\" y \"prueba\", divididos en 70%, 10% y 20% de los datos. Esta divisi칩n es com칰n dentro de la ciencia de datos y est치 basada en el *principio de Pareto*.\n",
    "\n",
    "Adem치s de la divisi칩n es necesario transformar el texto de cada tweet, pues recordemos cada texto puede contener emoticonos 游游游뻟릖游游쉻릖쓇릖, hashtags *#VivaLaMigraci칩n*, menciones a usuarios [@el_BID](https://twitter.com/el_bid?lang=es) y links a p치ginas externas. Algunos de estos elementos pueden contener informaci칩n 칰til para la detecci칩n de sentimiento y/o xenofobia (como los hashtags), pero otros pueden no ser nada informativos (como los nombres de usuario).\n",
    "\n",
    "##### Scikit learn\n",
    "Se trata de una librer칤a de c칩digo abierto enfocada en proveer herramientas de aprendizaje de m치quinas tales como modelos estad칤sticos y matem치ticos, as칤 como m칠tricas de evaluaci칩n comunes en algoritmos de aprendizaje de m치quinas.\n",
    "<figure>\n",
    "    <img src=\"./assets/images/scikit.png\"\n",
    "         alt=\"scikit-learn logo\"\n",
    "         style=\"max-width: 40%; height: auto\">\n",
    "    <figcaption>scikit-learn logo</figcaption>\n",
    "</figure>\n",
    "\n",
    "Esta librer칤a nos permitir치 dividir el conjunto de datos en los subconjuntos mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "#data reading\n",
    "import pandas as pd\n",
    "\n",
    "#data processing\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "import re\n",
    "\n",
    "#scikit-learn creacion de conjuntos de entrenamiento, prueba y validaci칩n\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando los datos etiquetados\n",
    "Se cargan los datos etiquetados en un DataFrame de pandas, el cual es una estructura de datos de alto rendimiento y f치cil de usar, que nos permite manipular los datos de forma eficiente. Para esta ocasi칩n solo se usan las columnas \"id\", \"text\" y \"label\" por motivos de simplicidad y confidencialidad. Los datos extra칤dos de Twitter se pueden recuperar a trav칠s del id del tweet y los datos guardadps en mongo DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>1386572116670271488</td>\n",
       "      <td>@OviedoJoelys Desde Per칰 aqu칤 una venezolana e...</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>1206336800282816512</td>\n",
       "      <td>@yanferluis @virginiatreyes Amiga, no desmayes...</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>1114601492206497792</td>\n",
       "      <td>Eso es nada. S칩lo en Venezuela hay m치s de 5.00...</td>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>1264945348499379968</td>\n",
       "      <td>@PeCazafantasmas @DanielaBrandon La verdad muy...</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>1294699845660413952</td>\n",
       "      <td>Los  migrantes pobres del mundo si est치n sufri...</td>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "5401  1386572116670271488  @OviedoJoelys Desde Per칰 aqu칤 una venezolana e...   \n",
       "3922  1206336800282816512  @yanferluis @virginiatreyes Amiga, no desmayes...   \n",
       "6465  1114601492206497792  Eso es nada. S칩lo en Venezuela hay m치s de 5.00...   \n",
       "8149  1264945348499379968  @PeCazafantasmas @DanielaBrandon La verdad muy...   \n",
       "9656  1294699845660413952  Los  migrantes pobres del mundo si est치n sufri...   \n",
       "\n",
       "            date  label  \n",
       "5401  2021-09-01      0  \n",
       "3922  2021-09-04      0  \n",
       "6465  2021-11-19      0  \n",
       "8149  2021-06-29      0  \n",
       "9656  2021-10-19      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./assets/data/xeno_data_workshop.csv')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostremos el texto de un tweet etiquetado como xenof칩bico y otro como no xenof칩bico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet marcado como xenof칩bo:\n",
      " @ahope71 @lopezobrador_ Es simple, parar los migrantes antes de llegar a M칠xico o siquiera mostrar la intenci칩n de hacerlo.\n",
      "Tweet marcado como NO xenof칩bo:\n",
      " Despu칠s de un 2018 de inmigrantes venezolanos tan fuerte viene una etapa m치s triste y de reencuentro.\n"
     ]
    }
   ],
   "source": [
    "print('Tweet marcado como xenof칩bo:\\n {}\\nTweet marcado como NO xenof칩bo:\\n {}'.format(data[data.label==1].sample(n=1).text.values[0], data[data.label==0].sample(n=1).text.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de textos\n",
    "\n",
    "Como ya se mencion칩, cada texto puede contener emoticonos, hashtags, menciones a usuarios y links a p치ginas externas. Algunos de estos elementos pueden contener informaci칩n 칰til para la detecci칩n de sentimiento y/o xenofobia (como los hashtags), pero otros pueden ser irrelevantes (como los nombres de usuario). Por lo tanto, es necesario limpiar el texto de cada tweet para que solo contenga palabras y signos de puntuaci칩n.\n",
    "\n",
    "Para clarificar el proceso de procesamiento de texto, se muestra un texto de ejemplo, generado sint칠ticamente, el cual contiene emojis, hastags, expresiones de risa, links a p치ginas web. Este ejemplo fue generado a modo de capturar la mayor cantidad de elementos que se pueden encontrar en un tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que opinas de la reformas Migratorias?游游 mi buen amigo @Pepe?\n",
      "Yo pienso que DEbieron facilitar la entrada de los inmigrantes 游누游游游뻟릖游游쉻릖쓇릖쬃눩#YoTeApoyo eeeexxxxxx jajajajaja. P치gina oficial del BID:          https://www.iadb.org/es \n"
     ]
    }
   ],
   "source": [
    "example_text = 'Que opinas de la reformas Migratorias?游游 mi buen amigo @Pepe?\\nYo pienso que DEbieron facilitar la entrada de los inmigrantes 游누游游游뻟릖游游쉻릖쓇릖쬃눩#YoTeApoyo eeeexxxxxx jajajajaja.'\n",
    "bid_url = ' P치gina oficial del BID:          https://www.iadb.org/es '\n",
    "example_text = example_text + bid_url\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesado de cada texto se deja a cargo del m칠todo `preprocess_tweet` el cual se encarga de transformar los emojis, hashtags, menciones a usuarios y links a p치ginas externas, normalizar las rizas y acortar palabras repetidas. Este m칠todo fue creado por el equipo de [Pysentimiento](https://github.com/pysentimiento/pysentimiento)\n",
    "\n",
    "Este m칠todo permite al usuario definir la transformaci칩n de cada elemento mencionado, por ejemplo, las menciones de usuario pueden ser modificadas a un token especial, como por ejemplo `@user`, `@usuario`, `@usr`, o pueden ser eliminadas del texto. La transformaci칩n a tokens especiales permite que el modelo aprenda a identificar este tipo de estructuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Que opinas de la reformas Migratorias?游游 mi buen amigo @usuario?\\nYo pienso que DEbieron facilitar la entrada de los inmigrantes 游누游游游뻟릖游游쉻릖쓇릖쬃눩hashtag yo te apoyo eexx jaja. P치gina oficial del BID:  url'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(example_text, user_token='@usuario', url_token='url', preprocess_hashtags=True, demoji=False, shorten=2, normalize_laughter=True, hashtag_token='hashtag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el texto cambia los links por la palabra definida \"url\", los nombres de usuario por \"@usuario\", separa las palabras contenidas en un hashtag y adem치s agrega \"hashtag\", normaliza las expresiones de risa y las letras repetidas. Describe el contenido de cada emoticono.\n",
    "\n",
    "Las palabras definidas ser치n muy 칰tiles para el modelo, pues 칠ste puede ser configurado para que considere dichas palabras como elementos estructurales y no como palabras.\n",
    "\n",
    "Sin embargo, se observa que el texto contiene espacios, mantiene los acentos, los saltos de l칤nea y las may칰sculas. Estas caracter칤sticas podr칤an ser no deseadas seg칰n el objetivo que se tiene y el modelo que se emplear치 para clasificar los textos. Ya que existen modelos que hacen diferencia entre estas caracter칤sticas y otros que no.\n",
    "\n",
    "Para sustituir multiples espacios en blanco (incluye saltos de linea) por un solo espacio en blanco se usa la expresi칩n regular `r'\\s+'`. Para el siguiente ejemplo se sustituyen los espacios en blanco por el s칤mbolo `#`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Que#opinas#de#la#reformas#Migratorias?游游#mi#buen#amigo#@Pepe?#Yo#pienso#que#DEbieron#facilitar#la#entrada#de#los#inmigrantes#游누游游游뻟릖游游쉻릖쓇릖쬃눩#YoTeApoyo#eeeexxxxxx#jajajajaja.#P치gina#oficial#del#BID:#https://www.iadb.org/es#'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove extra spaces\n",
    "re.compile(r'\\s+').sub('#', example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntemos estos conceptos para crear un m칠todo que nos permita limpiar el texto de cada tweet de manera autom치tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet, user_token='@usuario', url_token='url', hashtag_token='hashtag', preprocess_hashtags=True, demoji=True, shorten=2, normalize_laughter=True):\n",
    "    \"\"\"Function to clean a tweet\n",
    "\n",
    "    Args:\n",
    "        tweet (str): text to clean\n",
    "        user_token (str, optional): token to replace user mentions. Defaults to '@usuario'.\n",
    "        url_token (str, optional): token to replace urls. Defaults to 'url'.\n",
    "        hashtag_token (str, optional): token to replace hashtags. Defaults to 'hashtag'.\n",
    "        preprocess_hashtags (bool, optional): if True, hashtags are preprocessed. Defaults to True.\n",
    "        demoji (bool, optional): if True, emojis are replaced by their description. Defaults to True.\n",
    "        shorten (int, optional): if > 0, words are shortened to the specified length. Defaults to 2.\n",
    "        normalize_laughter (bool, optional): if True, laughter is normalized. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned tweet\n",
    "    \"\"\"\n",
    "    tweet = str(tweet)\n",
    "    tweet = preprocess_tweet(tweet, user_token=user_token, url_token=url_token, preprocess_hashtags=preprocess_hashtags, demoji=demoji, shorten=shorten, normalize_laughter=normalize_laughter, hashtag_token=hashtag_token)\n",
    "    tweet = re.compile(r'\\s+').sub(' ', tweet)\n",
    "    return tweet\n",
    "\n",
    "#apply function to all tweets\n",
    "data['text'] = data.text.apply(lambda x: clean_tweet(x))\n",
    "#remove initial and final spaces\n",
    "data['text'] = data.text.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el texto se ha limpiado correctamente, a trav칠s de la selecci칩n aleatoria de un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1166364172050980864,\n",
       "        '@usuario No. Considere la fuerza de trabajo en Chile total y el n칰mero de inmigrantes empleados . Ese ejercicio me dio algo como un 6.3. 12500 inmigrantes 6.6 % de la poblaci칩n 80% activos',\n",
       "        '2021-11-22', 0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisi칩n en conjuntos de entrenamiento, validaci칩n y prueba\n",
    "\n",
    "La divisi칩n en tres subconjuntos del conjunto de datos es de suma importancia, ya que cada uno de ellos juega un rol importante para la creaci칩n de un modelo de aprendizaje de m치quinas.\n",
    "\n",
    "* El conjunto de entrenamiento, es por lo regular, el que contiene m치s muestras, ya que a partir de estos datos el modelo debe aprender y/o generalizar las caracter칤sticas ling칲칤sticas de los tweets marcados como xen칩fobos y no xen칩fobos de la mejor forma posible. De esta manera, cuando el modelo deba clasificar un texto nuevo, su etiqueta sea correcta.\n",
    "\n",
    "* El conjunto de validaci칩n, es por lo regular, el que contiene menos muestras. Este conjunto nos permitir치 realizar m칰ltiples evaluaciones sobre el modelo, ya sea para determinar si existen mejoras al momento de variar cualquier par치metro involucrado con el modelo, aumentar el conjunto de entrenamiento o incluso evaluar la selecci칩n de modelos.\n",
    "\n",
    "* El conjunto de prueba nos permite realizar la evaluaci칩n final del modelo. Por lo regular este conjunto solo debe usarse una vez, esto para evitar posibles sesgos.\n",
    "\n",
    "En el aprendizaje de m치quinas es com칰n aplicar el principio de Pareto, el cual sostiene que la divisi칩n 칩ptima es 80% de los datos para entrenamiento y el restante para tareas de evaluaci칩n. Sin embargo, dado que se sabe que el modelo pasar치 por una serie de algoritmos de optimizaci칩n, s칤 se usara esta divisi칩n podr칤a lograrse un sesgo en cuanto al rendimiento real del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la divisi칩n en subconjuntos debe considerarse tambi칠n la siguiente pregunta 쮼l conjunto de datos total est치 balanceado? Al decir balanceado nos referimos a que las etiquetas disponibles son proporcionales entre s칤. Para nuestro caso, dado que se trabaja con 칰nicamente dos etiquetas, diremos que nuestro conjunto de datos es balanceado s칤 y s칩lo s칤 aproximadamente el 50% de los datos contienen la etiqueta *xen칩fobo*, y el restante corresponde a la etiqueta *no xenof칩bo*.\n",
    "\n",
    "Cuando el conjunto de datos se encuentra desbalanceado (como es el caso) la divisi칩n en subconjuntos debe hacerse con cuidado, a modo de distribuir proporcionalmente la o las clases m치s desbalanceadas en cada uno de los tres.\n",
    "\n",
    "Un ejemplo de omitir esta distribuci칩n puede suceder como sigue: Suponga que se tiene un conjunto de datos total de 1000 muestras, donde 780 corrresponden a la clase A y 220 a la clase B. Se hace la divisi칩n de forma aleatoria a modo de que el conjunto de entrenamiento contiene s칩lo 20 muestras de la clase B y 680 de la clase A. Tanto el conjunto de validaci칩n y prueba contendr치n 100 muestras de la clase A y 200 de la clase B. Dado que las muestras de la clase B en el conjunto de entrenamiento son pocas, el modelo no podr치 aprender lo suficiente de la clase B y por ende, su rendimiento para esta clase ser치 muy bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data before splitting for sanity\n",
    "data = data.sample(frac=1, ignore_index=True)\n",
    "\n",
    "#vamos a dividir el dataset por su id y etiqueta\n",
    "X = data.id.values\n",
    "y = data.label.values\n",
    "#genera los conjuntos de entrenamiento y prueba, se reparte equitativamente las etiquetas en cada conjunto\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, \n",
    "                                    y, test_size=0.2, random_state=2022, stratify=y)\n",
    "#de x_test y y_test, genera los conjuntos de prueba y validaci칩n\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.125, random_state=2022,\n",
    "                                                  stratify=y_train)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye los conjuntos de entrenamiento, prueba y validaci칩n a partir de la divisi칩n de los ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[data.id.isin(x_train)].reset_index(drop=True)\n",
    "test_df = data[data.id.isin(x_test)].reset_index(drop=True)\n",
    "valid_df = data[data.id.isin(x_val)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ojo veamos la distribuci칩n de las etiquetas en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5469\n",
       "1    1531\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of the labels by eye\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1256672684454359040</td>\n",
       "      <td>OJO Solidaridad emoji manos aplaudiendo emoji ...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1086709855673629952</td>\n",
       "      <td>@usuario @usuario Paga a hacienda, vuelve a Pe...</td>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199252043774464000</td>\n",
       "      <td>@usuario Una muy buena noticia para nuestros h...</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1308390290458320896</td>\n",
       "      <td>@usuario Cresta! Pobre gente y pobre de nosotr...</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1347265781424398336</td>\n",
       "      <td>@usuario Si fueran migrantes estar칤an transmit...</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1256672684454359040  OJO Solidaridad emoji manos aplaudiendo emoji ...   \n",
       "1  1086709855673629952  @usuario @usuario Paga a hacienda, vuelve a Pe...   \n",
       "2  1199252043774464000  @usuario Una muy buena noticia para nuestros h...   \n",
       "3  1308390290458320896  @usuario Cresta! Pobre gente y pobre de nosotr...   \n",
       "4  1347265781424398336  @usuario Si fueran migrantes estar칤an transmit...   \n",
       "\n",
       "         date  label  \n",
       "0  2021-08-16      0  \n",
       "1  2021-07-22      0  \n",
       "2  2021-11-15      0  \n",
       "3  2021-10-20      1  \n",
       "4  2021-10-03      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the final datasets\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda en un archivo de texto los conjuntos de entrenamiento, validaci칩n y prueba por separado, esto har치 m치s sencillo el entrenamiento y evaluaci칩n del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the datasets\n",
    "train_df.to_csv('./assets/data/train.csv', index=False)\n",
    "test_df.to_csv('./assets/data/test.csv', index=False)\n",
    "valid_df.to_csv('./assets/data/valid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('bid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cad67f8f08b43f52430a6b8684b01d2984f30490bfa5827628ebc9dc8cbf0dc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

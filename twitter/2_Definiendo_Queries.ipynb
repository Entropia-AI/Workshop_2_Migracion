{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-invention",
   "metadata": {},
   "source": [
    "# Definir Queries Útiles\n",
    "\n",
    "En esta notebook vamos a revisar una propuesta del proceso para definir queries que obtengan un volumen suficiente de tweets constantemente. Se usará de ejemplo el proceso realizado para el proyecto del Laboratorio de Migración.\n",
    "\n",
    "Para ello, se verán los siguientes puntos:\n",
    "- Identificar lenguajes y regiones a minar\n",
    "- Obtener un primer dataset\n",
    "- N-Grams para expandir queries\n",
    "- Proceso iterativo\n",
    "\n",
    "Nota: Para este proceso nos interesa obtener un volumen considerable de tweets, por lo que entre más días se puedan minar, mejor. En caso de contar con acceso [*Essential* o *Elevated*](https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-level) se recomienda [aplicar de manera gratuita a credenciales Académicas](https://developer.twitter.com/en/products/twitter-api/academic-research). Esta notebook se hacen queries dando por hecho que las credenciales son académicas. En el proyecto de Laboratorio de Migración se pudo obtener sin mayor problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pendulum\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from twarc.client2 import Twarc2\n",
    "from twarc.expansions import TWEET_FIELDS\n",
    "from twarc.expansions import ensure_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-chick",
   "metadata": {},
   "source": [
    "Nota: Estas son funciones desarrolladas por el equipo de entropia.ai, el código está en el directorio de helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.clean_tweets import clean_tweets_dataset\n",
    "from helpers.get_n_grams import get_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proud-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_TWITTER_API = {\n",
    "    'bearer_token': \"Enter your own Bearer token\",\n",
    "\n",
    "    # 'api_key': \"Enter your own API Key\",\n",
    "    # 'api_secret_key': \"Enter your own API Secret Key\",\n",
    "    # 'access_token': \"Enter your own access_token\",\n",
    "    # 'access_token_secret': \"Enter your own access_token_secret\"\n",
    "}\n",
    "\n",
    "IS_ACADEMIC = False # Cambiar a True, si las credenciales son Academicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-myanmar",
   "metadata": {},
   "source": [
    "Esta función es la que se encarga de minar los tweets, dada una lista de queries y un intervalo de tiempo. La notebook 1_Fundamentos_Twitter_API.ipynb contiene más detalles de qué es y como funciona la API de Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "equipped-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(credentials_api,\n",
    "               queries_list,\n",
    "               output_file,\n",
    "               since_date, until_date,\n",
    "               is_academic=False):\n",
    "    \"\"\"Function in charge of scrape tweets from the \n",
    "    official Twitter API, using the library named Twarc.\n",
    "\n",
    "    Args:\n",
    "        credentials_api (dict): Dictionary with the Twitter API credentials.\n",
    "        queries_list (list[str]): List of queries to scrape.\n",
    "        output_file (str): Path to the file in which to store the results.\n",
    "        since_date (datetime): Start of the time span to scrape.\n",
    "        until_date (datetime): End of the time span to scrape.\n",
    "        is_academic (bool, optional): If the credentials has Research \n",
    "                                      Academic access level.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instiate the Twarc Client\n",
    "    twarc_client = Twarc2(**credentials_api)\n",
    "\n",
    "    # Make some tweaks for using the research credentials\n",
    "    max_size = 100\n",
    "    tweet_fields = TWEET_FIELDS.copy()\n",
    "    search_func = twarc_client.search_recent\n",
    "    if(is_academic):\n",
    "        search_func = twarc_client.search_all\n",
    "        max_size = 500\n",
    "\n",
    "        # Remove the context_annotations attr to\n",
    "        # scrape 500 tweets per request\n",
    "        tweet_fields.remove('context_annotations')\n",
    "\n",
    "    tweet_fields = ','.join(tweet_fields)\n",
    "\n",
    "    with open(output_file, 'a') as pages_file:\n",
    "        for query in tqdm(queries_list):\n",
    "\n",
    "            search_results = search_func(query=query,\n",
    "                                         start_time=since_date,\n",
    "                                         end_time=until_date,\n",
    "                                         tweet_fields=tweet_fields,\n",
    "                                         max_results=max_size)\n",
    "\n",
    "            # Write all the obtained tweets\n",
    "            for page in search_results:\n",
    "\n",
    "                # Write one by one the tweets\n",
    "                for tweet in ensure_flattened(page):\n",
    "                    json.dump(tweet, pages_file, ensure_ascii=False)\n",
    "                    pages_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-nature",
   "metadata": {},
   "source": [
    "## Primer Dataset\n",
    "\n",
    "### Identificar países y lenguajes de interés\n",
    "Un primer paso es identificar en que lenguaje y países nos interesan minar, en el caso del Laboratorio de Migración se minan tweets de los países hispanohablantes de LATAM (español), países del caribe (inglés) y Brasil (portugués). Dependiendo de que tanto se habla ese idioma en el mundo y los países que nos interesa cubrir, van a cambiar que tan específicos o generales pueden que ser los queries y qué operadores usaríamos.\n",
    "\n",
    "### Ejemplos proyecto Laboratorio de Migración\n",
    "\n",
    "### Inglés\n",
    "Tweets en inglés se publican desde todas partes del mundo y en este caso, solo nos interesan ciertos países que por densidad de población no pueden generar un gran volumen de tweets. Por lo que si no usamos el operador `place_country`, vamos a obtener tweets de todo el mundo y eso significaría invertir más tiempo y recursos en el minado, procesamiento, etc. Para evitar esto, desde ya se puede definir que usaremos el operador `place_country` para así limitar la búsqueda de tweets a esos países y esto nos dará la oportunidad de usar keywords con un alcance más abierto. \n",
    "\n",
    "En el ejemplo de migración se podrían usar: `migrants, immigrants, emigrants, migration, immigration, emigration, migratory, immigratory y emigratory` y luego añadir variaciones como `pro-migrants, anti-migrants, ...`\n",
    "\n",
    "Query ejemplo: `(migrants OR immigrants OR emigrants OR migration OR immigration OR emigration OR migratory OR immigratory OR emigratory) (place_country:BB OR place_country:GY OR place_country:BZ OR place_country:JM OR place_country:HT OR place_country:SR)`\n",
    "\n",
    "### Portugués\n",
    "En este caso, los tweets en portugués van a ser principalmente de Brasil o de Portugal, por lo que se podría aplicar el operador `place_country` para obtener solo tweets publicados desde Brasil o minar queries sin ninguna restricción para luego filtrarlos basándose en sí son geo-localizables a otro lado que no sea Brasil. \n",
    "\n",
    "Palabras claves podrían ser: `migratórias, migração, migrações, migrantes, migradas`\n",
    "\n",
    "Query ejemplo: `(migratórias OR migração OR migrações OR migrantes OR migradas) place_country:BR`\n",
    "\n",
    "### Español\n",
    "Para este lenguaje, exceptuando a España, nos interesa obtener tweets del conjunto de países que van a generar la mayoría de tweets en español. Y aunque es buena práctica utilizar queries más general junto con el operador `place_country`, esto nos dejaría con un volumen muy inferior y que no terminaría de reflejar las conversaciones reales de lo que se podría obtener.\n",
    "\n",
    "Por lo que aquí conviene hacer ambas cosas, tener queries con keywords generales, pero cerrado a solo los países de interés y tener queries con keywords más específicos, pero sin ninguna limitación de geolocalización, para luego tratar de extraer el país de origen por otros atributos (Esto se va a revisar en la notebook llamada 3_Variables_Demograficas.ipynb).\n",
    "\n",
    "Query ejemplo: `(migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (place_country:MX OR place_country:AR OR place_country:AR)`.\n",
    "\n",
    "Esto se replicaría para todos los países que nos interesa y nos serviría como primer dataset para iterar sobre los queries. No solo para los queries con el filtro por país, también para aquellos que no lo tienen, ya que esos debe de ser más específicos para no traernos demasiado ruido, pero que cubran la mayor parte de la conversación y así tener un volumen suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-magic",
   "metadata": {},
   "source": [
    "Para esta notebook usaremos de ejemplo la definición de queries en español, y como se mencionó previamente, el primer paso es definir una lista preliminar de keywords y concatenarlas con el operador `OR`. Optar por palabras que de manera explícita hable del tema de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "respected-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keywords = [\"migrar\", \"inmigrar\", \"emigrar\", \n",
    "                 \"migrante\", \"inmigrante\", \"emigrante\", \n",
    "                 \"migrantes\", \"inmigrantes\", \"emigrantes\", \n",
    "                 \"migratorios\", \"inmigratorios\", \"emigratorios\", \n",
    "                 \"migratorias\", \"inmigratorias\", \"emigratorias\"]\n",
    "list_keywords = ' OR '.join(list_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-daily",
   "metadata": {},
   "source": [
    "En seguida hay que añadir los operadores para filtrar por países. Esto nos ayudará a encontrar keywords o expresiones que estén atadas al contexto de cada país, ayudando así a filtrar un poco la conversación migratoria.\n",
    "\n",
    "También se añade el operador `-is:retweet` y `lang:es`, evitando traer retweets, ya que por el momento solo nos interesa obtener los tweets únicos y que estén en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authentic-sociology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (place_country:MX OR place_country:AR OR place_country:CO) lang:es -is:retweet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_queries = f\"({list_keywords}) (place_country:MX OR place_country:AR OR place_country:CO) lang:es -is:retweet\"\n",
    "lst_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-nursery",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-brave",
   "metadata": {},
   "source": [
    "Definimos un intervalo de tiempo considerable para obtener un volumen útil de tweets. En el proyecto del Laboratorio de Migración se empezó con minar tweets de todo el año 2019 y 2020, al ser tanto tiempo, podremos obtener tweets de momentos en los que ocurrieran eventos relacionados con migración, así como en momentos donde sea un tema menos viral. \n",
    "Para este ejemplo usaremos todo lo que va del 2022.\n",
    "\n",
    "Nota: Todos los archivos que se obtengan durante el desarrollo de esta notebook se van a encontrar en el directorio: \"./files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saved-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_queries = [lst_queries]\n",
    "\n",
    "date_start = pendulum.datetime(year=2022, month=1, day=1)\n",
    "date_end = pendulum.datetime(year=2022, month=9, day=10)\n",
    "\n",
    "file_tweets = os.path.abspath(\"./files/1_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-apple",
   "metadata": {},
   "source": [
    "Se ejecuta la función para minar los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:27<00:00, 87.22s/it]\n"
     ]
    }
   ],
   "source": [
    "get_tweets(credentials_api = CREDENTIALS_TWITTER_API,\n",
    "           queries_list = lst_queries,\n",
    "           output_file = file_tweets,\n",
    "           since_date = date_start, \n",
    "           until_date = date_end,\n",
    "           is_academic= IS_ACADEMIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-transportation",
   "metadata": {},
   "source": [
    "Vemos cuantos tweets obtuvimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "northern-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8769 ./files/1_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./files/1_dataset.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-exhibition",
   "metadata": {},
   "source": [
    "Estos 8,593 tweets nos van a servir como primer dataset para identificar keywords nuevas que estén relacionadas con el fenómeno que queremos estudiar, ya sea que se refieran a el de manera:\n",
    "- Explicita: \"migrante\" o \"inmigrantes\" \n",
    "- Implícita: \"los mexicanos en estado unidos\" o \"las personas ilegales\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-volume",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-honolulu",
   "metadata": {},
   "source": [
    "### N-Grams\n",
    "\n",
    "Estas son un concepto muy utilizado en el procesamiento de lenguaje natural (NLP, por siglas en inglés), y se pueden entender como una secuencia de N palabras, por ejemplo:\n",
    "- Dream on (2-Grama)\n",
    "- Kickstart My Heart (3-Grama)\n",
    "- Hail to the King (4-Grama)\n",
    "\n",
    "Estas secuencias de texto se pueden contabilizar en un corpus de texto y obtener la frecuencia de aparición de una palabra tras la otra, y así saber qué palabras puede considerarse como una sola entidad. Por ejemplo, en un texto sobre la historia de la banda de rock Aerosmith, el 2-grama \"Dream On\" se puede considerar una sola palabra, dado que se refiere a la canción que sirvió como soundtrack de la película  Armagedon. También puede servir para realizar una predicción de qué palabras siguen, como el autocompletado que realiza Spotify para mostrar una lista de opciones de la canción original y covers cuando solo escribimos \"Kick Start...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-playlist",
   "metadata": {},
   "source": [
    "Podemos considerar los N-Grams como una herramienta útil para encontrar patrones entre los tweets que hablan sobre migración y así extender la lista de keywords y/o formar queries que se apoyen en que un tweet contenga al menos dos keywords.\n",
    "\n",
    "Primero hay que preprocesar los tweets para así pasar todo a minúsculas y eliminar partes del texto que no sean de utilidad:\n",
    "- URLs\n",
    "- Números\n",
    "- Emojis\n",
    "- Caracteres especiales\n",
    "- Risas (Jajaj o Hahaha)\n",
    "- Espacios en blanco múltiples\n",
    "- Mención a usuarios \n",
    "- Borrar stopwords (que, como, cuál, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-disaster",
   "metadata": {},
   "source": [
    "Para lograr hacer esto primero hay que cargar los identificadores únicos (IDs) y textos de los tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lesbian-nancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1568384770672934912</td>\n",
       "      <td>Una amiga d Zuvic si matrícula de abogada y ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1568384665731440640</td>\n",
       "      <td>En la Convención Internacional de #EmergenciaC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1568357940461191168</td>\n",
       "      <td>@Hugo_Gutierrez_ La gente rechazó por llevarle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1568337671931691008</td>\n",
       "      <td>Participamos en las actividades en conmemoraci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568333644934135808</td>\n",
       "      <td>El día del inmigrante es una oportunidad para ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>1477088691877261312</td>\n",
       "      <td>Sin duda, fue un año de mucho trabajo. Y nos p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>1477088689901682688</td>\n",
       "      <td>💇‍♀️ Servimos de escuela para capacitar a 125 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>1477086472469684224</td>\n",
       "      <td>@GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>1477067319830478848</td>\n",
       "      <td>@denadastotales @alfiemart Pero si con ese mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>1477067149873238016</td>\n",
       "      <td>Tengo un conocido que es chavista, vive en Chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8769 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text\n",
       "0     1568384770672934912  Una amiga d Zuvic si matrícula de abogada y ap...\n",
       "1     1568384665731440640  En la Convención Internacional de #EmergenciaC...\n",
       "2     1568357940461191168  @Hugo_Gutierrez_ La gente rechazó por llevarle...\n",
       "3     1568337671931691008  Participamos en las actividades en conmemoraci...\n",
       "4     1568333644934135808  El día del inmigrante es una oportunidad para ...\n",
       "...                   ...                                                ...\n",
       "8764  1477088691877261312  Sin duda, fue un año de mucho trabajo. Y nos p...\n",
       "8765  1477088689901682688  💇‍♀️ Servimos de escuela para capacitar a 125 ...\n",
       "8766  1477086472469684224  @GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...\n",
       "8767  1477067319830478848  @denadastotales @alfiemart Pero si con ese mod...\n",
       "8768  1477067149873238016  Tengo un conocido que es chavista, vive en Chi...\n",
       "\n",
       "[8769 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_json(\"./files/1_dataset.jsonl\", lines=True)\n",
    "df_tweets = df_tweets[['id', 'text']]\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dying-lying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1568384770672934912</td>\n",
       "      <td>Una amiga d Zuvic si matrícula de abogada y ap...</td>\n",
       "      <td>amiga zuvic matricula abogada aportante campan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1568384665731440640</td>\n",
       "      <td>En la Convención Internacional de #EmergenciaC...</td>\n",
       "      <td>convencion internacional emergenciaclimatica c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1568357940461191168</td>\n",
       "      <td>@Hugo_Gutierrez_ La gente rechazó por llevarle...</td>\n",
       "      <td>gente rechazo llevarle boric inmigrantes compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1568337671931691008</td>\n",
       "      <td>Participamos en las actividades en conmemoraci...</td>\n",
       "      <td>participamos actividades conmemoracion inmigra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568333644934135808</td>\n",
       "      <td>El día del inmigrante es una oportunidad para ...</td>\n",
       "      <td>inmigrante oportunidad valorar patria argentin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>1477088691877261312</td>\n",
       "      <td>Sin duda, fue un año de mucho trabajo. Y nos p...</td>\n",
       "      <td>duda ano preparamos continuaremos luchando der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>1477088689901682688</td>\n",
       "      <td>💇‍♀️ Servimos de escuela para capacitar a 125 ...</td>\n",
       "      <td>servimos escuela capacitar migrantes peluqueri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>1477086472469684224</td>\n",
       "      <td>@GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...</td>\n",
       "      <td>culpables inmigrantes muertos chiapa cirzo bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>1477067319830478848</td>\n",
       "      <td>@denadastotales @alfiemart Pero si con ese mod...</td>\n",
       "      <td>modelo rico top pib per capital destino millon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>1477067149873238016</td>\n",
       "      <td>Tengo un conocido que es chavista, vive en Chi...</td>\n",
       "      <td>conocido chavista vive chile opina gobierno ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8767 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0     1568384770672934912  Una amiga d Zuvic si matrícula de abogada y ap...   \n",
       "1     1568384665731440640  En la Convención Internacional de #EmergenciaC...   \n",
       "2     1568357940461191168  @Hugo_Gutierrez_ La gente rechazó por llevarle...   \n",
       "3     1568337671931691008  Participamos en las actividades en conmemoraci...   \n",
       "4     1568333644934135808  El día del inmigrante es una oportunidad para ...   \n",
       "...                   ...                                                ...   \n",
       "8764  1477088691877261312  Sin duda, fue un año de mucho trabajo. Y nos p...   \n",
       "8765  1477088689901682688  💇‍♀️ Servimos de escuela para capacitar a 125 ...   \n",
       "8766  1477086472469684224  @GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...   \n",
       "8767  1477067319830478848  @denadastotales @alfiemart Pero si con ese mod...   \n",
       "8768  1477067149873238016  Tengo un conocido que es chavista, vive en Chi...   \n",
       "\n",
       "                                      text_preprocessed  \n",
       "0     amiga zuvic matricula abogada aportante campan...  \n",
       "1     convencion internacional emergenciaclimatica c...  \n",
       "2     gente rechazo llevarle boric inmigrantes compr...  \n",
       "3     participamos actividades conmemoracion inmigra...  \n",
       "4     inmigrante oportunidad valorar patria argentin...  \n",
       "...                                                 ...  \n",
       "8764  duda ano preparamos continuaremos luchando der...  \n",
       "8765  servimos escuela capacitar migrantes peluqueri...  \n",
       "8766  culpables inmigrantes muertos chiapa cirzo bur...  \n",
       "8767  modelo rico top pib per capital destino millon...  \n",
       "8768  conocido chavista vive chile opina gobierno ch...  \n",
       "\n",
       "[8767 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = clean_tweets_dataset(df_tweets, doc_column='text', clean_col='text_preprocessed')\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-ballot",
   "metadata": {},
   "source": [
    "Obtener bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "european-fisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noecampos/.pyenv/versions/BID/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "srs_bigrams = get_n_grams(df_tweets['text_preprocessed'], \n",
    "                          n_gram = 2, \n",
    "                          n_top = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "centered-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram</th>\n",
       "      <th>total_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poblacion migrante</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrantes venezolanos</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personas migrantes</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prov inmigrante</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brenas capital</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>capital prov</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>forasteros inmigrantes</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>barrio grave</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fomentan sosobra</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gracias loscontenedoresdebasura</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grave gracias</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inmigrantes fomentan</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>inseguridad barrio</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>loscontenedoresdebasura unico</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sosobra intimidan</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traido forasteros</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unico traido</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cantidad inmigrantes</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bogota inseguridad</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atractivo senorial</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>carecia atractivo</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>carnero papas</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>comida eterno</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cordoba rosario</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cosmopolita cantidad</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>eterno carnero</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fondas mundo</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>inmigrantes recien</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llegados carecia</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>papas fondas</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>recien llegados</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rosario cosmopolita</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>senorial comida</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ciudades cordoba</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>contraste ciudades</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>derechos humanos</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>migrantes refugiados</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mujeres migrantes</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lasbrenas brenas</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>aves migratorias</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>libresdelsur barriosdepie</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>migrante venezolana</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>san antonio</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>barriosdepie lasbrenas</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>guardia nacional</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>noticias asm</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>merendero comedor</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>atencion migrantes</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>migrantes muertos</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>lopez obrador</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>migrantes mexicanos</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>refugiados migrantes</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nacional migracion</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>proteccion temporal</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>comunidad migrante</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>instituto nacional</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>publicar foto</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>acaba publicar</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>entrega merienda</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>registro unico</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             n_gram  total_freq\n",
       "0                poblacion migrante         253\n",
       "1             migrantes venezolanos         229\n",
       "2                personas migrantes         145\n",
       "3                   prov inmigrante         133\n",
       "4                    brenas capital         132\n",
       "5                      capital prov         132\n",
       "6            forasteros inmigrantes         117\n",
       "7                      barrio grave         116\n",
       "8                  fomentan sosobra         116\n",
       "9   gracias loscontenedoresdebasura         116\n",
       "10                    grave gracias         116\n",
       "11             inmigrantes fomentan         116\n",
       "12               inseguridad barrio         116\n",
       "13    loscontenedoresdebasura unico         116\n",
       "14                sosobra intimidan         116\n",
       "15                traido forasteros         116\n",
       "16                     unico traido         116\n",
       "17             cantidad inmigrantes         114\n",
       "18               bogota inseguridad         113\n",
       "19               atractivo senorial         108\n",
       "20                carecia atractivo         108\n",
       "21                    carnero papas         108\n",
       "22                    comida eterno         108\n",
       "23                  cordoba rosario         108\n",
       "24             cosmopolita cantidad         108\n",
       "25                   eterno carnero         108\n",
       "26                     fondas mundo         108\n",
       "27               inmigrantes recien         108\n",
       "28                 llegados carecia         108\n",
       "29                     papas fondas         108\n",
       "30                  recien llegados         108\n",
       "31              rosario cosmopolita         108\n",
       "32                  senorial comida         108\n",
       "33                 ciudades cordoba         107\n",
       "34               contraste ciudades         107\n",
       "35                 derechos humanos          99\n",
       "36             migrantes refugiados          94\n",
       "37                mujeres migrantes          79\n",
       "38                 lasbrenas brenas          78\n",
       "39                 aves migratorias          68\n",
       "40        libresdelsur barriosdepie          64\n",
       "41              migrante venezolana          60\n",
       "42                      san antonio          60\n",
       "43           barriosdepie lasbrenas          58\n",
       "44                 guardia nacional          57\n",
       "45                     noticias asm          57\n",
       "46                merendero comedor          53\n",
       "47               atencion migrantes          51\n",
       "48                migrantes muertos          49\n",
       "49                    lopez obrador          47\n",
       "50              migrantes mexicanos          47\n",
       "51             refugiados migrantes          47\n",
       "52               nacional migracion          46\n",
       "53              proteccion temporal          46\n",
       "54               comunidad migrante          45\n",
       "55               instituto nacional          45\n",
       "56                    publicar foto          44\n",
       "57                   acaba publicar          43\n",
       "58                 entrega merienda          43\n",
       "59                   registro unico          43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_bigrams[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-caution",
   "metadata": {},
   "source": [
    "Obtener trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "failing-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noecampos/.pyenv/versions/BID/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "srs_trigramas = get_n_grams(df_tweets['text_preprocessed'], \n",
    "                            n_gram = 3, \n",
    "                            n_top = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "understood-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram</th>\n",
       "      <th>total_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brenas capital prov</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital prov inmigrante</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barrio grave gracias</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fomentan sosobra intimidan</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forasteros inmigrantes fomentan</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gracias loscontenedoresdebasura unico</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grave gracias loscontenedoresdebasura</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inmigrantes fomentan sosobra</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inseguridad barrio grave</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loscontenedoresdebasura unico traido</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>traido forasteros inmigrantes</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unico traido forasteros</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bogota inseguridad barrio</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>atractivo senorial comida</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cantidad inmigrantes recien</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>carecia atractivo senorial</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>carnero papas fondas</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>comida eterno carnero</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cordoba rosario cosmopolita</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cosmopolita cantidad inmigrantes</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   n_gram  total_freq\n",
       "0                     brenas capital prov         132\n",
       "1                 capital prov inmigrante         132\n",
       "2                    barrio grave gracias         116\n",
       "3              fomentan sosobra intimidan         116\n",
       "4         forasteros inmigrantes fomentan         116\n",
       "5   gracias loscontenedoresdebasura unico         116\n",
       "6   grave gracias loscontenedoresdebasura         116\n",
       "7            inmigrantes fomentan sosobra         116\n",
       "8                inseguridad barrio grave         116\n",
       "9    loscontenedoresdebasura unico traido         116\n",
       "10          traido forasteros inmigrantes         116\n",
       "11                unico traido forasteros         116\n",
       "12              bogota inseguridad barrio         113\n",
       "13              atractivo senorial comida         108\n",
       "14            cantidad inmigrantes recien         108\n",
       "15             carecia atractivo senorial         108\n",
       "16                   carnero papas fondas         108\n",
       "17                  comida eterno carnero         108\n",
       "18            cordoba rosario cosmopolita         108\n",
       "19       cosmopolita cantidad inmigrantes         108"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_trigramas[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-accounting",
   "metadata": {},
   "source": [
    "Explorando esta lista de n-gramas encontraremos que:\n",
    "- Las palabras \"migrante\", \"inmigrante\" o \"emigrante\" viene acompañadas de:\n",
    "  - población\n",
    "  - personas\n",
    "  - forasteros\n",
    "  - inseguridad\n",
    "  - muertos\n",
    "  - refugiados\n",
    "  - niños\n",
    "  - caravana\n",
    "  - ilegales\n",
    "  - plaza\n",
    "  - venezolano\n",
    "  - hermanos\n",
    "  - familias\n",
    "  - mujer\n",
    "  - atención\n",
    "  - grupo\n",
    "  - países\n",
    "  - retornados\n",
    "  - miles\n",
    "  - millones\n",
    "  - tráfico\n",
    "\n",
    "\n",
    "- Las palabras \"migratorio\" y \"migratoria\" vienen acompañadas de:\n",
    "  - leyes\n",
    "  - política\n",
    "  - temas\n",
    "  - pacto\n",
    "  - reformas\n",
    "  - crisis\n",
    "  - fenómeno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-socket",
   "metadata": {},
   "source": [
    "## Primer query basado en N-Grams\n",
    "Con el grupo de palabras listadas previamente, se construye un primer query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pediatric-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_query = \"(migrante OR inmigrante OR emigrante) (niño OR mujer OR ilegal OR muerto OR persona OR hermano OR forastero OR refugiado OR retornado OR familia OR caravana OR grupo OR población OR pais OR miles OR millones OR plaza OR trafico OR inseguridad OR atención OR venezolano)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-therapist",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-factor",
   "metadata": {},
   "source": [
    "A este primer query se le añade variaciones de las palabras, por ejemplo:\n",
    "- migrante ⨪> migrantes, inmigrante, ...\n",
    "- niño -> niños, niña, niñas\n",
    "- caravana -> caravanas\n",
    "- refugiado -> refugiados, refugiada, refugiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "present-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_query = \"(migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes) (niño OR niños OR niña OR niñas OR mujer OR mujeres OR hombre OR hombres OR ilegal OR ilegales OR muerto OR muertos OR persona OR personas OR hermano OR hermanos OR hermana OR hermanas OR forastero OR forasteros OR forastera OR forasteras OR refugiado OR refugiados OR refugiada OR refugiadas OR familia OR familias OR caravana OR caravanas OR grupo OR grupos OR población OR poblaciones OR pais OR paises OR miles OR millones OR plaza OR plazas OR trafico OR inseguridad OR atención OR venezolano)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-logistics",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-merchandise",
   "metadata": {},
   "source": [
    "Esto se repite para las palabras migratorio y migratoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "operating-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_query = \"(migratorio OR migratoria OR migratorios OR migratorias OR inmigratorio OR inmigratoria OR inmigratorios OR inmigratorias OR emigratorio OR emigratoria OR emigratorios OR emigratorias) (ley OR leyes OR politica OR politicas OR tema OR temas OR pacto OR pactos OR reforma OR reformas OR fenomeno OR crisis)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-championship",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-terminology",
   "metadata": {},
   "source": [
    "Aprovechando que estamos trabajando con credenciales con acceso academico, podriamos incluso juntar estos dos queries con un OR para así ahorrar tiempo y requests a la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spanish-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_query = f\"({first_query}) OR ({second_query})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-swing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-routine",
   "metadata": {},
   "source": [
    "Añadimos el operador de `has:geo` pero negado: `-has:geo` y los operadores para evitar retweets y filtrar al español. Con esto vamos a obtener tweets que cumplan con los keywords y que no tengan información de geolocalización. Esto porque aquellos que tengan información de alguna ciudad o país, ya nos los trajimos con los queries que tienen el operador `place_country`. \n",
    "\n",
    "Para el proyecto del Laboratorio de Migración se hizo de esta manera, y aquellos tweets que no tuvieran información de geolocalización dada por Twitter se intentó inferir por medio de los atributos, *description* y *location* del usuario. Esto se verá en la siguiente notebook llamada \"3_Get_Location.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "future-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes) (niño OR niños OR niña OR niñas OR mujer OR mujeres OR hombre OR hombres OR ilegal OR ilegales OR muerto OR muertos OR persona OR personas OR hermano OR hermanos OR hermana OR hermanas OR forastero OR forasteros OR forastera OR forasteras OR refugiado OR refugiados OR refugiada OR refugiadas OR familia OR familias OR caravana OR caravanas OR grupo OR grupos OR población OR poblaciones OR pais OR paises OR miles OR millones OR plaza OR plazas OR trafico OR inseguridad OR atención OR venezolano)) OR ((migratorio OR migratoria OR migratorios OR migratorias OR inmigratorio OR inmigratoria OR inmigratorios OR inmigratorias OR emigratorio OR emigratoria OR emigratorios OR emigratorias) (ley OR leyes OR politica OR politicas OR tema OR temas OR pacto OR pactos OR reforma OR reformas OR fenomeno OR crisis)) -has:geo lang:es -is:retweet\n"
     ]
    }
   ],
   "source": [
    "merge_query = f\"({first_query}) OR ({second_query}) -has:geo lang:es -is:retweet\"\n",
    "print(merge_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-kingston",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-resort",
   "metadata": {},
   "source": [
    "Dado que minar todo lo que va del 2022 tomaría mucho tiempo, aprovecharemos que la API de Twitter nos permite hacer un conteo de tweets dado un query, para así saber cuantos tweets obtendríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "finite-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:17,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "twarc_client = Twarc2(**CREDENTIALS_TWITTER_API)\n",
    "counts_per_month = twarc_client.counts_all(query=merge_query,\n",
    "                                           start_time=date_start,\n",
    "                                           end_time=date_end,\n",
    "                                           granularity='day')\n",
    "\n",
    "df_all = []\n",
    "for month_count in tqdm(counts_per_month): \n",
    "    df_all.append(pd.DataFrame(month_count['data']))\n",
    "    \n",
    "df_all = pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tamil-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si se minaran lo que va del año 2022 se obtendrian 2654060 tweets\n"
     ]
    }
   ],
   "source": [
    "print(f\"Si se minaran lo que va del año 2022 se obtendrian {df_all['tweet_count'].sum()} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-executive",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-telescope",
   "metadata": {},
   "source": [
    "Pero aun así se puede hacer el ejercicio de minar un par de días"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "studied-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_queries = [merge_query]\n",
    "\n",
    "date_start = pendulum.datetime(year=2022, month=9, day=9)\n",
    "date_end = pendulum.datetime(year=2022, month=9, day=11)\n",
    "\n",
    "file_tweets = os.path.abspath(\"./files/2_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "decreased-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:12<00:00, 132.03s/it]\n"
     ]
    }
   ],
   "source": [
    "get_tweets(credentials_api = CREDENTIALS_TWITTER_API,\n",
    "           queries_list = lst_queries,\n",
    "           output_file = file_tweets,\n",
    "           since_date = date_start, \n",
    "           until_date = date_end,\n",
    "           is_academic= IS_ACADEMIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "forty-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13680 ./files/2_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./files/2_dataset.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-philosophy",
   "metadata": {},
   "source": [
    "Con minar solo un par de días, se obtuvo mucho más volumen que en todo el año, con el conjunto de queries abiertos pero filtrado a ciertos países. Mientras que si mináramos todo lo que va del año obtendríamos 2,654,167 tweets únicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-polls",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-collaboration",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-oliver",
   "metadata": {},
   "source": [
    "## Más keywords\n",
    "\n",
    "Uno de los objetivos del proyecto Laboratorio de Migración es llevar un track de la conversación xenófoba dentro de la conversación migrante. Es decir, tweets que estén atacando e insultado a los migrantes, refugiados, etc. Con esto se le dará más profundidad al estudio de la conversación de la migración, dado que ahora también se podría estimar que porcentaje de ella es con un tono xenófobo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-strategy",
   "metadata": {},
   "source": [
    "Para asegurar que se obtendran tweets en ese tono, se hizo el mismo ejercicio de queries abiertas y filtros por paises pero ya no solo con keywords abiertos, sino que usando operadores logicos se concatenaron con palabras que fueran racistas o xenofobas. Y se aplico el proce de N-Grams para extender esta lista de palabras.\n",
    "\n",
    "Por ejemplo, buscar tweets que contengan la palabra `migrante` y variaciones pero concatenadas con un `AND` a palabras como `malditos, ilegales, violadores, ladrones, terroristas`.\n",
    "\n",
    "Query ejemplo: `((migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes) (malditos OR maldito OR ilegales OR ilegal OR violadores OR violador OR ladrones OR ladron OR terroristas OR terrorista)) (place_country:MX OR place_country:AR OR place_country:AR)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-command",
   "metadata": {},
   "source": [
    "Primero vamos a minar nuevos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "split-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (malditos OR maldito OR ilegales OR ilegal OR violadores OR violador OR ladrones OR ladron OR terroristas OR terrorista)) (place_country:MX OR place_country:AR OR place_country:CO) lang:es -is:retweet'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query = \"(migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (malditos OR maldito OR ilegales OR ilegal OR violadores OR violador OR ladrones OR ladron OR terroristas OR terrorista)\"\n",
    "new_query = f\"({new_query}) (place_country:MX OR place_country:AR OR place_country:CO) lang:es -is:retweet\"\n",
    "new_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-suspension",
   "metadata": {},
   "source": [
    "Nota: Por cuestiones de volumen, se minara todo 2020, 2021 y 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "miniature-porcelain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.33s/it]\n"
     ]
    }
   ],
   "source": [
    "new_query = [new_query]\n",
    "\n",
    "date_start = pendulum.datetime(year=2020, month=1, day=1)\n",
    "date_end = pendulum.datetime(year=2022, month=9, day=10)\n",
    "\n",
    "file_tweets = os.path.abspath(\"./files/3_dataset.jsonl\")\n",
    "\n",
    "get_tweets(credentials_api = CREDENTIALS_TWITTER_API,\n",
    "           queries_list = new_query,\n",
    "           output_file = file_tweets,\n",
    "           since_date = date_start, \n",
    "           until_date = date_end,\n",
    "           is_academic= IS_ACADEMIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stopped-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683 ./files/3_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./files/3_dataset.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-sociology",
   "metadata": {},
   "source": [
    "#### Extraer N-Grams al nuevo dataset\n",
    "\n",
    "Nuevamente, se utiliza la técnica de N-Grams para obtener queries que sirvan para minar tweets, ahora siendo sobre migración y xenófobos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "renewable-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noecampos/.pyenv/versions/BID/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_tweets = pd.read_json(\"./files/3_dataset.jsonl\", lines=True)\n",
    "df_tweets = df_tweets[['id', 'text']]\n",
    "\n",
    "df_tweets = clean_tweets_dataset(df_tweets, doc_column='text', clean_col='text_preprocessed')\n",
    "\n",
    "srs_bigrams = get_n_grams(df_tweets['text_preprocessed'], \n",
    "                          n_gram = 2, \n",
    "                          n_top = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-platform",
   "metadata": {},
   "source": [
    "Y con esto se consiguieron nuevas palabras, por ejemplo:\n",
    "- delincuentes\n",
    "- mafiosos\n",
    "- ignorantes\n",
    "- crimen organizado\n",
    "- agresores\n",
    "- crimen\n",
    "- traficantes\n",
    "- drogadictos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-circus",
   "metadata": {},
   "source": [
    "Con estas nuevas palabras se puede armar un nuevo query para el minado sin restricción por países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "roman-toronto",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:18,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "new_query = \"(migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes) (malditos OR maldito OR ilegales OR ilegal OR violar OR violadores OR violador OR ladrones OR ladron OR terrorismo OR terroristas OR terrorista OR delincuencia OR delincuentes OR delincuente OR mafia OR mafiosos OR mafioso OR ignorantes OR ignorante OR agredir OR agresores OR agresor OR crimen OR criminal OR criminales OR trafico OR traficantes OR traficante OR drogadictos OR drogradictas OR drogradicto OR drogradicta)\"\n",
    "new_query = f\"({new_query}) -has:geo lang:es -is:retweet\"\n",
    "\n",
    "date_start = pendulum.datetime(year=2022, month=1, day=1)\n",
    "date_end = pendulum.datetime(year=2022, month=9, day=10)\n",
    "\n",
    "twarc_client = Twarc2(**CREDENTIALS_TWITTER_API)\n",
    "counts_per_month = twarc_client.counts_all(query=new_query,\n",
    "                                           start_time=date_start,\n",
    "                                           end_time=date_end,\n",
    "                                           granularity='day')\n",
    "\n",
    "df_all = []\n",
    "for month_count in tqdm(counts_per_month): \n",
    "    df_all.append(pd.DataFrame(month_count['data']))\n",
    "    \n",
    "df_all = pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "comparable-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si se minaran lo que va del año 2022 se obtendrian 142994 tweets\n"
     ]
    }
   ],
   "source": [
    "print(f\"Si se minaran lo que va del año 2022 se obtendrian {df_all['tweet_count'].sum()} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-theater",
   "metadata": {},
   "source": [
    "Este nuevo query obtendría 142,994 tweets en lo que va del año. Hay que tener en cuenta que probablemente haya tweets que este query traiga tweets duplicados que existan dentro de los posibles 2 millones de tweets previamente contados, pero es muy fácil lidiar con tweets duplicados dado que todos tienen un ID único."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-overall",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-divorce",
   "metadata": {},
   "source": [
    "## Iterar el ejercicio\n",
    "\n",
    "Este ejercicio se tiene que repetir con cada dataset que vayamos generando hasta que consideramos que generamos un volumen suficiente. No hay una métrica escrita en piedra, por lo que es cuestión de iterar múltiples veces, añadiendo y quitando keywords. Algo útil y rápido para ver si nuestras keywords/operadores obtienen tweets es [utilizar la búsqueda avanzada dentro del portal de Twitter](https://help.twitter.com/es/using-twitter/twitter-advanced-search), con ella podremos tener una vista rápida de si obtiene tweets o no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-allergy",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-intent",
   "metadata": {},
   "source": [
    "- [ ] Añadir nota sobre los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-exploration",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-guatemala",
   "metadata": {},
   "source": [
    "## Queries para pipelines nuevos del BID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-effects",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BID",
   "language": "python",
   "name": "bid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

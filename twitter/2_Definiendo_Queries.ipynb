{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pendulum\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from twarc.client2 import Twarc2\n",
    "from twarc.expansions import TWEET_FIELDS\n",
    "from twarc.expansions import ensure_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.clean_tweets import clean_tweets_dataset\n",
    "from helpers.get_n_grams import get_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "devoted-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_TWITTER_API = {\n",
    "    'bearer_token': \"Enter your own Bearer token\",\n",
    "\n",
    "    # 'api_key': \"Enter your own API Key\",\n",
    "    # 'api_secret_key': \"Enter your own API Secret Key\",\n",
    "    # 'access_token': \"Enter your own access_token\",\n",
    "    # 'access_token_secret': \"Enter your own access_token_secret\"\n",
    "}\n",
    "\n",
    "IS_ACADEMIC = False # Cambiar a True, si las credenciales son Academicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "natural-tonight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_tweets(credentials_api,\n",
    "               queries_list,\n",
    "               output_file,\n",
    "               since_date, until_date,\n",
    "               is_academic=False):\n",
    "    \"\"\"Function in charge of scrape tweets from the \n",
    "    official Twitter API, using the library named Twarc.\n",
    "\n",
    "    Args:\n",
    "        credentials_api (dict): Dictionary with the Twitter API credentials.\n",
    "        queries_list (list[str]): List of queries to scrape.\n",
    "        output_file (str): Path to the file in which to store the results.\n",
    "        since_date (datetime): Start of the time span to scrape.\n",
    "        until_date (datetime): End of the time span to scrape.\n",
    "        is_academic (bool, optional): If the credentials has Research \n",
    "                                      Academic access level.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instiate the Twarc Client\n",
    "    twarc_client = Twarc2(**credentials_api)\n",
    "\n",
    "    # Make some tweaks for using the research credentials\n",
    "    max_size = 100\n",
    "    tweet_fields = TWEET_FIELDS.copy()\n",
    "    search_func = twarc_client.search_recent\n",
    "    if(is_academic):\n",
    "        search_func = twarc_client.search_all\n",
    "        max_size = 500\n",
    "\n",
    "        # Remove the context_annotations attr to\n",
    "        # scrape 500 tweets per request\n",
    "        tweet_fields.remove('context_annotations')\n",
    "\n",
    "    tweet_fields = ','.join(tweet_fields)\n",
    "\n",
    "    with open(output_file, 'a') as pages_file:\n",
    "        for query in tqdm(queries_list):\n",
    "\n",
    "            search_results = search_func(query=query,\n",
    "                                         start_time=since_date,\n",
    "                                         end_time=until_date,\n",
    "                                         tweet_fields=tweet_fields,\n",
    "                                         max_results=max_size)\n",
    "\n",
    "            # Write all the obtained tweets\n",
    "            for page in search_results:\n",
    "\n",
    "                # Write one by one the tweets\n",
    "                for tweet in ensure_flattened(page):\n",
    "                    json.dump(tweet, pages_file, ensure_ascii=False)\n",
    "                    pages_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-stomach",
   "metadata": {},
   "source": [
    "# Definir Queries √ötiles\n",
    "\n",
    "En esta notebook vamos a revisar una propuesta del proceso que se puede seguir para definir queries que ayuden a obtener un volumen suficiente de tweets constantemente. Se usar√° de ejemplo el proceso realizado para el proyecto del Laboratorio de Migraci√≥n.\n",
    "\n",
    "Para ello, se veran los siguientes puntos:\n",
    "- Queries para un primer dataset\n",
    "- N-Grams para expandir dataset\n",
    "- Proceso iterativo\n",
    "- A√±adir operadores de regi√≥n y lenguaje\n",
    "\n",
    "Nota: Para este proceso nos interesa obtener un volumen considerable de tweets, por lo que entre m√°s d√≠as se puedan minar, mejor. En caso de contar con acceso [*Essential* o *Elevated*](https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-level) se recomienda [aplicar de manera gratuita a credenciales Acad√©micas](https://developer.twitter.com/en/products/twitter-api/academic-research). \n",
    "\n",
    "TO-DO: Precedente de credenciales academicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-workshop",
   "metadata": {},
   "source": [
    "## Primer Dataset\n",
    "\n",
    "### Identificar pa√≠ses y lenguajes de inter√©s\n",
    "Un primer paso es identificar en que lenguaje vamos a minar, en el caso del Laboratorio de Migraci√≥n se minan tweets de los pa√≠ses hispanohablantes de LATAM (espa√±ol), pa√≠ses del caribe (ingl√©s) y Brasil (portugu√©s). Dependiendo de que tanto se habla ese idioma en el mundo y los pa√≠ses que nos interesa cubrir, van a cambiar que tan espec√≠ficos o generales pueden que ser los queries y qu√© operadores usar√≠amos.\n",
    "\n",
    "### Ejemplos proyecto Laboratorio de Migraci√≥n\n",
    "\n",
    "### Ingl√©s\n",
    "Tweets en ingl√©s se publican desde todas partes del mundo y en este caso, solo nos interesan ciertos pa√≠ses que por densidad de poblaci√≥n no pueden generar un gran volumen de tweets. Por lo que si no usamos el operador `place_country`, vamos a obtener tweets de todo el mundo y eso significar√≠a invertir m√°s tiempo y recursos en el minado, procesamiento, etc. Para evitar esto, desde ya se puede definir que usaremos el operador `place_country` para as√≠ limitar la b√∫squeda de tweets a esos pa√≠ses y esto nos dar√° la oportunidad de usar keywords con un alcance m√°s abierto. \n",
    "\n",
    "En el ejemplo de migraci√≥n se podr√≠an usar: `migrants, immigrants, emigrants, migration, immigration, emigration, migratory, immigratory y emigratory` y luego a√±adir variaciones como `pro-migrants, anti-migrants, ...`\n",
    "\n",
    "El query podria ser: `(migrants OR immigrants OR emigrants OR migration OR immigration OR emigration OR migratory OR immigratory OR emigratory) (place_country:BB OR place_country:GY OR place_country:BZ OR place_country:JM OR place_country:HT OR place_country:SR)`\n",
    "\n",
    "### Portugu√©s\n",
    "En este caso, los tweets en portugu√©s van a venir de Brasil o de Portugal principalmente, por lo que se podr√≠a aplicar el operador `place_country` para obtener solo tweets publicados desde Brasil o minar queries sin ninguna restricci√≥n para luego filtrarlos bas√°ndose en s√≠ son geo-localizables a otro lado que no sea Brasil. \n",
    "\n",
    "Palabras claves podrian ser: `migrat√≥rias, migra√ß√£o, migra√ß√µes, migrantes, migradas`\n",
    "\n",
    "El query podria ser: `(migrat√≥rias OR migra√ß√£o OR migra√ß√µes OR migrantes OR migradas) place_country:BR`\n",
    "\n",
    "### Espa√±ol\n",
    "Para este lenguaje, exceptuando a Espa√±a, nos interesa obtener tweets del conjunto que van a generar la mayoria de tweets en espa√±ol. Y aunque es buena pr√°ctica utilizar queries m√°s generales junto con el operador `place_country`, esto nos dejar√≠a con un volumen muy inferior y que no terminar√≠a de reflejar las conversaciones reales de lo que se podr√≠a obtener.\n",
    "\n",
    "Por lo que aqu√≠ conviene hacer ambas cosas, tener queries con keywords generales, pero cerrado a solo los pa√≠ses de inter√©s y tener queries con keywords m√°s espec√≠ficos, pero sin ninguna limitaci√≥n de geolocalizaci√≥n, para luego tratar de extraer el pa√≠s de origen por otros atributos (Esto est√° en la siguiente notebook).\n",
    "\n",
    "Un query ejemplo podr√≠a ser: `(migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (place_country:MX OR place_country:AR OR place_country:AR)`. Esto se replicar√≠a para todos los pa√≠ses que nos interesa y nos servir√≠a como primer dataset para iterar sobre los queries. No solo para los queires con el filtro por pais, tambien para aquellos que no lo tienen, ya que esos debe de ser m√°s especificos para no traernos demasiado ruido pero que cubran la mayor parate de la conversaci√≥n para as√≠ tener un volumen suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-cancellation",
   "metadata": {},
   "source": [
    "Para esta notebook usaremos de ejemplo la definici√≥n de queries en espa√±ol, y como se mencion√≥ previamente, el primer paso es definir una lista preliminar de keywords y concatenarlas con el operador `OR`. Optar por palabras que de manera expl√≠cita hable del tema de inter√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civilian-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keywords = [\"migrar\", \"inmigrar\", \"emigrar\", \n",
    "                 \"migrante\", \"inmigrante\", \"emigrante\", \n",
    "                 \"migrantes\", \"inmigrantes\", \"emigrantes\", \n",
    "                 \"migratorios\", \"inmigratorios\", \"emigratorios\", \n",
    "                 \"migratorias\", \"inmigratorias\", \"emigratorias\"]\n",
    "list_keywords = ' OR '.join(list_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-bryan",
   "metadata": {},
   "source": [
    "En seguida hay que a√±adir los operadores del pais de interes. Esto nos ayudara a encontrar keywords o expresiones que esten atadas al contexto de cada pais, ayudando asi a filtrar un poco la conversaci√≥n migratoria a los paises de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arabic-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(migrar OR inmigrar OR emigrar OR migrante OR inmigrante OR emigrante OR migrantes OR inmigrantes OR emigrantes OR migratorios OR inmigratorios OR emigratorios OR migratorias OR inmigratorias OR emigratorias) (place_country:MX OR place_country:AR OR place_country:CO)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_queries = f\"({list_keywords}) (place_country:MX OR place_country:AR OR place_country:CO)\"\n",
    "lst_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-bobby",
   "metadata": {},
   "source": [
    "Definimos un intervalo de tiempo considerable para obtener un volumen √∫til de tweets. En el proyecto del Laboratorio de Migraci√≥n se empez√≥ con minar tweets de todo el a√±o 2019 y 2020, al ser tanto tiempo, podremos obtener tweets de momentos en los que ocurrieran eventos relacionados a migraci√≥n, as√≠ como en momentos donde sea un tema menos viral. \n",
    "\n",
    "Para este ejemplo usaremos todo lo que va del 2022.\n",
    "\n",
    "Nota: Todos los archivos que se obtengan durante el desarrollo de esta notebook se van a encontrar en el directorio \"./archivos_queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statewide-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_queries = [lst_queries]\n",
    "\n",
    "date_start = pendulum.datetime(year=2022, month=1, day=1)\n",
    "date_end = pendulum.datetime(year=2022, month=9, day=1)\n",
    "\n",
    "file_tweets = os.path.abspath(\"./archivos_queries/1_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-packing",
   "metadata": {},
   "source": [
    "Se ejecuta la funci√≥n para minar los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "horizontal-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:25<00:00, 85.51s/it]\n"
     ]
    }
   ],
   "source": [
    "get_tweets(credentials_api = CREDENTIALS_TWITTER_API,\n",
    "           queries_list = lst_queries,\n",
    "           output_file = file_tweets,\n",
    "           since_date = date_start, \n",
    "           until_date = date_end,\n",
    "           is_academic= IS_ACADEMIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-passport",
   "metadata": {},
   "source": [
    "Vemos cuantos tweets obtuvimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silent-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8584 ./archivos_queries/1_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./archivos_queries/1_dataset.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-lyric",
   "metadata": {},
   "source": [
    "Estos 8,590 tweets nos van a servir como primer dataset para empezar a identificar keywords que esten relacionadas con el fenomeno que queremos estudiar, ya sea que se refieran a el de manera :\n",
    "- Explicita como lo es decir \"migrante\" o \"inmigrantes\" \n",
    "- Implicito como \"los mexicanos en estado unidos\" o \"las personas ilegales\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-series",
   "metadata": {},
   "source": [
    "Para lograr hacer esto primero hay que cargar los identificadores unicos (IDs) y textos de los tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "false-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565119364566847488</td>\n",
       "      <td>En el Centro de Jubilados Un Sue√±o de B¬∞ La Es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565104878166446080</td>\n",
       "      <td>El Grupo de Asuntos √âtnicos, Migrantes y Refug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565103949337837568</td>\n",
       "      <td>Lanzamiento de #INTEGRATE de @alcaldiabogota @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565102572586909696</td>\n",
       "      <td>@AntaresVazAla Por supuesto, pl√°tica del foro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565095116074876928</td>\n",
       "      <td>Por fin entendieron que los nietos tenemos el ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1477088691877261312</td>\n",
       "      <td>Sin duda, fue un a√±o de mucho trabajo. Y nos p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>1477088689901682688</td>\n",
       "      <td>üíá‚Äç‚ôÄÔ∏è Servimos de escuela para capacitar a 125 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>1477086472469684224</td>\n",
       "      <td>@GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>1477067319830478848</td>\n",
       "      <td>@denadastotales @alfiemart Pero si con ese mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>1477067149873238016</td>\n",
       "      <td>Tengo un conocido que es chavista, vive en Chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8584 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text\n",
       "0     1565119364566847488  En el Centro de Jubilados Un Sue√±o de B¬∞ La Es...\n",
       "1     1565104878166446080  El Grupo de Asuntos √âtnicos, Migrantes y Refug...\n",
       "2     1565103949337837568  Lanzamiento de #INTEGRATE de @alcaldiabogota @...\n",
       "3     1565102572586909696  @AntaresVazAla Por supuesto, pl√°tica del foro ...\n",
       "4     1565095116074876928  Por fin entendieron que los nietos tenemos el ...\n",
       "...                   ...                                                ...\n",
       "8579  1477088691877261312  Sin duda, fue un a√±o de mucho trabajo. Y nos p...\n",
       "8580  1477088689901682688  üíá‚Äç‚ôÄÔ∏è Servimos de escuela para capacitar a 125 ...\n",
       "8581  1477086472469684224  @GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...\n",
       "8582  1477067319830478848  @denadastotales @alfiemart Pero si con ese mod...\n",
       "8583  1477067149873238016  Tengo un conocido que es chavista, vive en Chi...\n",
       "\n",
       "[8584 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_json(\"./archivos_queries/1_dataset.jsonl\", lines=True)\n",
    "df_tweets = df_tweets[['id', 'text']]\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-particular",
   "metadata": {},
   "source": [
    "### N-Grams\n",
    "\n",
    "Estas son un concepto muy utilizado en el procesamiento de lenguaje natural (NLP, por siglas en ingles), y se pueden entender como una secuencia de N palabras, por ejemplo:\n",
    "- Dream on (2-Grams)\n",
    "- Kickstart My Heart (3-Grams)\n",
    "- Hail to the King (4-Grams)\n",
    "\n",
    "Estas secuencias de texto se pueden contabilizar en un corpus de texto y obtener la frecuencia de aparici√≥n de una palabra tras la otra, y as√≠ saber qu√© palabras puede considerarse como una sola entidad. Por ejemplo, en un texto sobre la historia de la banda de rock Aerosmith el 2-gram \"Dream On\" se puede considerar una sola palabra, dado que se refiere a la canci√≥n que sirvi√≥ como soundtrack de la pelicula  Armagedon. Tambi√©n puede servir para realizar una predicci√≥n de que palabras siguen, como el autocompletado que realiza Spotify para mostrar una lista de opciones de la canci√≥n original y covers cuando solo escribimos \"Kick Start...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-playlist",
   "metadata": {},
   "source": [
    "Podemos considerar los N-Grams como una herramienta util para encontrar patrones entre los tweets que hablan sobre migraci√≥n y as√≠ extender la lista de keywords y/o formar queries que se apoyen en que un tweet contenga al menos dos keywords.\n",
    "\n",
    "Primero hay que preprocesar los tweets para as√≠ eliminar partes del texto que no sean de utilidad y pasar todo a minusculas, por ejemplo:\n",
    "- URLs\n",
    "- Numeros\n",
    "- Emojis\n",
    "- Caracteres especiales\n",
    "- Risas (Jajaj o Hahaha)\n",
    "- Espacios en blanco multiples\n",
    "- Mencion a usuarios\n",
    "- Borrar stopwords (que, como, cual, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "differential-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565119364566847488</td>\n",
       "      <td>En el Centro de Jubilados Un Sue√±o de B¬∞ La Es...</td>\n",
       "      <td>centro jubilados sueno estrella pudimos compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565104878166446080</td>\n",
       "      <td>El Grupo de Asuntos √âtnicos, Migrantes y Refug...</td>\n",
       "      <td>grupo asuntos etnicos migrantes refugiados per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565103949337837568</td>\n",
       "      <td>Lanzamiento de #INTEGRATE de @alcaldiabogota @...</td>\n",
       "      <td>lanzamiento integrate brindara atencion migran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565102572586909696</td>\n",
       "      <td>@AntaresVazAla Por supuesto, pl√°tica del foro ...</td>\n",
       "      <td>platica foro sao paulo socialismo cuba venezue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565095116074876928</td>\n",
       "      <td>Por fin entendieron que los nietos tenemos el ...</td>\n",
       "      <td>entendieron nietos derecho adoptar doble ciuda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1477088691877261312</td>\n",
       "      <td>Sin duda, fue un a√±o de mucho trabajo. Y nos p...</td>\n",
       "      <td>duda ano preparamos continuaremos luchando der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>1477088689901682688</td>\n",
       "      <td>üíá‚Äç‚ôÄÔ∏è Servimos de escuela para capacitar a 125 ...</td>\n",
       "      <td>servimos escuela capacitar migrantes peluqueri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>1477086472469684224</td>\n",
       "      <td>@GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...</td>\n",
       "      <td>culpables inmigrantes muertos chiapa cirzo bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>1477067319830478848</td>\n",
       "      <td>@denadastotales @alfiemart Pero si con ese mod...</td>\n",
       "      <td>modelo rico top pib per capital destino millon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>1477067149873238016</td>\n",
       "      <td>Tengo un conocido que es chavista, vive en Chi...</td>\n",
       "      <td>conocido chavista vive chile opina gobierno ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8469 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0     1565119364566847488  En el Centro de Jubilados Un Sue√±o de B¬∞ La Es...   \n",
       "1     1565104878166446080  El Grupo de Asuntos √âtnicos, Migrantes y Refug...   \n",
       "2     1565103949337837568  Lanzamiento de #INTEGRATE de @alcaldiabogota @...   \n",
       "3     1565102572586909696  @AntaresVazAla Por supuesto, pl√°tica del foro ...   \n",
       "4     1565095116074876928  Por fin entendieron que los nietos tenemos el ...   \n",
       "...                   ...                                                ...   \n",
       "8579  1477088691877261312  Sin duda, fue un a√±o de mucho trabajo. Y nos p...   \n",
       "8580  1477088689901682688  üíá‚Äç‚ôÄÔ∏è Servimos de escuela para capacitar a 125 ...   \n",
       "8581  1477086472469684224  @GSandovalSalas @DIF_NMX @GobiernoMX @SRE_mx @...   \n",
       "8582  1477067319830478848  @denadastotales @alfiemart Pero si con ese mod...   \n",
       "8583  1477067149873238016  Tengo un conocido que es chavista, vive en Chi...   \n",
       "\n",
       "                                      text_preprocessed  \n",
       "0     centro jubilados sueno estrella pudimos compar...  \n",
       "1     grupo asuntos etnicos migrantes refugiados per...  \n",
       "2     lanzamiento integrate brindara atencion migran...  \n",
       "3     platica foro sao paulo socialismo cuba venezue...  \n",
       "4     entendieron nietos derecho adoptar doble ciuda...  \n",
       "...                                                 ...  \n",
       "8579  duda ano preparamos continuaremos luchando der...  \n",
       "8580  servimos escuela capacitar migrantes peluqueri...  \n",
       "8581  culpables inmigrantes muertos chiapa cirzo bur...  \n",
       "8582  modelo rico top pib per capital destino millon...  \n",
       "8583  conocido chavista vive chile opina gobierno ch...  \n",
       "\n",
       "[8469 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = clean_tweets_dataset(df_tweets, doc_column='text', clean_col='text_preprocessed')\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numeric-fusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noecampos/.pyenv/versions/BID/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram</th>\n",
       "      <th>total_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poblacion migrante</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrantes venezolanos</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personas migrantes</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prov inmigrante</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brenas capital</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>etnicos migrantes</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>frontera sur</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>migrantes centroamericanos</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>temas migratorios</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>atencion migrante</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        n_gram  total_freq\n",
       "0           poblacion migrante         243\n",
       "1        migrantes venezolanos         229\n",
       "2           personas migrantes         136\n",
       "3              prov inmigrante         130\n",
       "4               brenas capital         129\n",
       "..                         ...         ...\n",
       "95           etnicos migrantes          25\n",
       "96                frontera sur          25\n",
       "97  migrantes centroamericanos          25\n",
       "98           temas migratorios          25\n",
       "99           atencion migrante          24\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_ngrams = get_n_grams(df_tweets['text_preprocessed'])\n",
    "srs_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "resistant-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_gram</th>\n",
       "      <th>total_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>unico migrantes</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ninos ninas</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>foto brenas</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>migrantes refugiadas</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>miles migrantes</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ninos migrantes</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>venezolanos rumv</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>permiso proteccion</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>antonio texas</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>atencion poblacion</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>caravana migrante</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ganas emigrar</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>inmigrantes ilegales</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>millones migrantes</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ninez migrante</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>plaza inmigrantes</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>temporal ppt</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>migrante venezolano</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>hermanos migrantes</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ee uu</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>familias migrantes</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>mujer migrante</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>salto angel</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>america latina</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>asociacion salto</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>calidad vida</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>caravanas migrantes</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>casa migrante</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>estatuto temporal</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>migrantes mexico</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>sueno americano</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>trailer texas</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>asuntos etnicos</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>centro integracion</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>eduardo flores</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>etnicos migrantes</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>frontera sur</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>migrantes centroamericanos</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>temas migratorios</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>atencion migrante</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        n_gram  total_freq\n",
       "60             unico migrantes          42\n",
       "61                 ninos ninas          40\n",
       "62                 foto brenas          38\n",
       "63        migrantes refugiadas          38\n",
       "64             miles migrantes          36\n",
       "65             ninos migrantes          36\n",
       "66            venezolanos rumv          35\n",
       "67          permiso proteccion          34\n",
       "68               antonio texas          31\n",
       "69          atencion poblacion          31\n",
       "70           caravana migrante          31\n",
       "71               ganas emigrar          30\n",
       "72        inmigrantes ilegales          30\n",
       "73          millones migrantes          30\n",
       "74              ninez migrante          30\n",
       "75           plaza inmigrantes          30\n",
       "76                temporal ppt          30\n",
       "77         migrante venezolano          29\n",
       "78          hermanos migrantes          28\n",
       "79                       ee uu          27\n",
       "80          familias migrantes          27\n",
       "81              mujer migrante          27\n",
       "82                 salto angel          27\n",
       "83              america latina          26\n",
       "84            asociacion salto          26\n",
       "85                calidad vida          26\n",
       "86         caravanas migrantes          26\n",
       "87               casa migrante          26\n",
       "88           estatuto temporal          26\n",
       "89            migrantes mexico          26\n",
       "90             sueno americano          26\n",
       "91               trailer texas          26\n",
       "92             asuntos etnicos          25\n",
       "93          centro integracion          25\n",
       "94              eduardo flores          25\n",
       "95           etnicos migrantes          25\n",
       "96                frontera sur          25\n",
       "97  migrantes centroamericanos          25\n",
       "98           temas migratorios          25\n",
       "99           atencion migrante          24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs_ngrams[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-skating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BID",
   "language": "python",
   "name": "bid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

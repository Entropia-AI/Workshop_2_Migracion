{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "center-original",
   "metadata": {},
   "source": [
    "# Asignar g√©nero\n",
    "\n",
    "El poder asignar un g√©nero a los tweets nos permite hacer un estudio de como los diferentes g√©neros abordan el tema de estudio, en este caso el de Migraci√≥n. Twitter no recolecta esa informaci√≥n al hacer la cuenta, por lo que no podemos encontrar un atributo dado por la API, pero al igual que la geolocalizaci√≥n, podemos inferirla a partir de atributos como el nombre, la descripci√≥n.\n",
    "\n",
    "En esta notebook se van a revisar algunas opciones para asignar g√©nero al autor:\n",
    "- Buscar nombres t√≠picamente masculinos o femeninos en los campos de username, descripci√≥n\n",
    "- Buscar pronombres (She/Her o He/His) en la descripci√≥n del usuario\n",
    "- Buscar la nacionalidad (e.g.: Mexicano / Mexicana) en los campos descripci√≥n\n",
    "\n",
    "Tambi√©n se podr√≠a trabajar con adjetivos, profesiones, oficios o t√≠tulos.\n",
    "\n",
    "Nota: Dado que estos campos son abiertos y el nivel de veracidad recae completamente en cada usuario, se puede esperar que estos m√©todos tengan falsos positivos o negativos. Igualmente, tampoco se puede esperar que se termine asignando un g√©nero a todos los autores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perceived-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import helpers.preprocess_text as pre_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-encounter",
   "metadata": {},
   "source": [
    "## Cargar nombres, pronombres, nacionalidades y g√©neros\n",
    "\n",
    "En el directorio llamado ./resources hay un archivo llamado names_genders.csv que contiene una columna con nombres, una con el g√©nero que t√≠picamente tienen las personas llamadas as√≠ y una √∫ltima columna de si es un nombre compuesto como; Maria Jose o Jose Guadalupe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaningful-utilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guadalupe</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jose</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sofia</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angel</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jesus</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>aron</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>jose guadalupe</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>jose maria</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>maria guadalupe</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>maria jose</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name gender  is_double\n",
       "0          guadalupe      F      False\n",
       "1               jose      M      False\n",
       "2              sofia      F      False\n",
       "3              angel      M      False\n",
       "4              jesus      M      False\n",
       "..               ...    ...        ...\n",
       "555             aron      M      False\n",
       "556   jose guadalupe      M       True\n",
       "557       jose maria      M       True\n",
       "558  maria guadalupe      F       True\n",
       "559       maria jose      F       True\n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names = pd.read_csv('./resources/names_genders.csv')\n",
    "\n",
    "pre_text.remove_duplicated_chars(df_names, 'name')\n",
    "\n",
    "# Names composed\n",
    "df_names_double = df_names[df_names['is_double']]\n",
    "regex_names_double = f\"\\\\b((?:{'|'.join(df_names_double['name'])}))\\\\b\"\n",
    "regex_names_double = re.compile(regex_names_double)\n",
    "\n",
    "# Single names\n",
    "df_names_single = df_names[~df_names['is_double']]\n",
    "regex_names_single = f\"\\\\b((?:{'|'.join(df_names_single['name'])}))\\\\b\"\n",
    "regex_names_single = re.compile(regex_names_single)\n",
    "\n",
    "# Names to gender\n",
    "dict_names_gender = df_names.set_index('name')['gender'].to_dict()\n",
    "df_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-vaccine",
   "metadata": {},
   "source": [
    "Despues hay un diccionario con los posibles strings conteniendo pronombres y el genero que identifican. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frozen-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pronouns_gender = {\n",
    "    \"she her\": 'F',\n",
    "    \"her she\": 'F',\n",
    "    \"he him\": 'M',\n",
    "    \"him he\": 'M'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-metadata",
   "metadata": {},
   "source": [
    "Un diccionario con las posibles nacionalidades en las diferentes variaciones segun el genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polish-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nationalities_gender = {\n",
    "    'mexicano': 'M',\n",
    "    'mexicana': 'F',\n",
    "    'colombiano': 'M',\n",
    "    'colombiana': 'F',\n",
    "    'argentino': 'M',\n",
    "    'argentina': 'F'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-fleet",
   "metadata": {},
   "source": [
    "### Cargar tweets\n",
    "\n",
    "Primero hay que cargar los tweets, espec√≠ficamente el ID del tweet, el ID del usuario, el nombre del autor, su descripci√≥n. Los √∫ltimos tres campos son abiertos, es decir, que el usuario puede ingresar lo que desee a excepci√≥n de algunos caracteres especiales. Esto implica que antes de todo hay que pre-procesarlos para as√≠ reducir el n√∫mero de variantes para una misma nacionalidad y/o nombre.\n",
    "\n",
    "Nota: Usaremos de ejemplo el primer dataset que se obtuvo en la notebook \"2_Definiendo_Queries.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-error",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565119364566847488</td>\n",
       "      <td>1423647858650136576</td>\n",
       "      <td>Subsecretar√≠a de Gobierno</td>\n",
       "      <td>MUNICIPALIDAD  DE SAN MIGUEL - BUENOS AIRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565104878166446080</td>\n",
       "      <td>195947504</td>\n",
       "      <td>Personer√≠a Distrital de Medell√≠n</td>\n",
       "      <td>#PorTusDerechosM√°sCerca #SomosPersoner√≠a #Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565103949337837568</td>\n",
       "      <td>286819842</td>\n",
       "      <td>Sim√≥n Gamboa</td>\n",
       "      <td>activista Colombovenezolanoüáªüá™üá®üá¥ |concejal de C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565102572586909696</td>\n",
       "      <td>1284595923754999808</td>\n",
       "      <td>Cesar Cortes</td>\n",
       "      <td>100% neoliberal, 100% aspiracionista, 100% mex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565095116074876928</td>\n",
       "      <td>1333482129716604928</td>\n",
       "      <td>Mauro Grande</td>\n",
       "      <td>I'm stuck in a city but I belong in a field.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1477088691877261312</td>\n",
       "      <td>397706715</td>\n",
       "      <td>FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>Trabajamos por la inclusi√≥n, el respeto y la i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>1477088689901682688</td>\n",
       "      <td>397706715</td>\n",
       "      <td>FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>Trabajamos por la inclusi√≥n, el respeto y la i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>1477086472469684224</td>\n",
       "      <td>1176580744036196352</td>\n",
       "      <td>GaelAlejandro</td>\n",
       "      <td>¬°Estoy vivooo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>1477067319830478848</td>\n",
       "      <td>579360940</td>\n",
       "      <td>Juan Farre</td>\n",
       "      <td>#11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>1477067149873238016</td>\n",
       "      <td>326540841</td>\n",
       "      <td>YUNNYS L.</td>\n",
       "      <td>Ing. Industrial~UNEXPO.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8584 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id            author_id  \\\n",
       "0     1565119364566847488  1423647858650136576   \n",
       "1     1565104878166446080            195947504   \n",
       "2     1565103949337837568            286819842   \n",
       "3     1565102572586909696  1284595923754999808   \n",
       "4     1565095116074876928  1333482129716604928   \n",
       "...                   ...                  ...   \n",
       "8579  1477088691877261312            397706715   \n",
       "8580  1477088689901682688            397706715   \n",
       "8581  1477086472469684224  1176580744036196352   \n",
       "8582  1477067319830478848            579360940   \n",
       "8583  1477067149873238016            326540841   \n",
       "\n",
       "                           author_name  \\\n",
       "0            Subsecretar√≠a de Gobierno   \n",
       "1     Personer√≠a Distrital de Medell√≠n   \n",
       "2                         Sim√≥n Gamboa   \n",
       "3                         Cesar Cortes   \n",
       "4                         Mauro Grande   \n",
       "...                                ...   \n",
       "8579        FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà   \n",
       "8580        FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà   \n",
       "8581                     GaelAlejandro   \n",
       "8582                        Juan Farre   \n",
       "8583                         YUNNYS L.   \n",
       "\n",
       "                                     author_description  \n",
       "0           MUNICIPALIDAD  DE SAN MIGUEL - BUENOS AIRES  \n",
       "1     #PorTusDerechosM√°sCerca #SomosPersoner√≠a #Pers...  \n",
       "2     activista Colombovenezolanoüáªüá™üá®üá¥ |concejal de C...  \n",
       "3     100% neoliberal, 100% aspiracionista, 100% mex...  \n",
       "4     I'm stuck in a city but I belong in a field.\\n...  \n",
       "...                                                 ...  \n",
       "8579  Trabajamos por la inclusi√≥n, el respeto y la i...  \n",
       "8580  Trabajamos por la inclusi√≥n, el respeto y la i...  \n",
       "8581                                     ¬°Estoy vivooo!  \n",
       "8582                                                #11  \n",
       "8583                            Ing. Industrial~UNEXPO.  \n",
       "\n",
       "[8584 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_json(\"./archivos_queries/1_dataset.jsonl\", lines=True)\n",
    "df_tweets = df_tweets[['id', 'author_id', 'author']]\n",
    "\n",
    "df_tweets['author_name'] = df_tweets['author'].apply(lambda x: x['name'])\n",
    "df_tweets['author_description'] = df_tweets['author'].apply(lambda x: x['description'])\n",
    "\n",
    "df_tweets = df_tweets.drop(columns=['author'])\n",
    "\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-criterion",
   "metadata": {},
   "source": [
    "Para evitar trabajar con autores duplicados, trabajaremos solo con una copia √∫nica de los autores, asignaremos g√©neros y luego haremos JOIN a los tweets usando como llave la columna `author_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crazy-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1423647858650136576</td>\n",
       "      <td>Subsecretar√≠a de Gobierno</td>\n",
       "      <td>MUNICIPALIDAD  DE SAN MIGUEL - BUENOS AIRES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1333482129716604928</td>\n",
       "      <td>Mauro Grande</td>\n",
       "      <td>I'm stuck in a city but I belong in a field.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>492397405</td>\n",
       "      <td>Magdalena Ayala</td>\n",
       "      <td>Hay que hacerse cargo de lo que uno dice, fin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132020962</td>\n",
       "      <td>Johanna Saenz</td>\n",
       "      <td>Mam√°. Polit√≥loga. Ms en Estudios Latinoamerica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4106090319</td>\n",
       "      <td>„ÄΩÔ∏è‚òï</td>\n",
       "      <td>1997.\\n‚Ä¢     Club Atl√©tico River Plateüêì‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>377788360</td>\n",
       "      <td>Eduardo D√≠atriü§çüíô‚ù§Ô∏è‚òÆÔ∏èüíõüíô</td>\n",
       "      <td>Productor y asociado para espect√°culos mayores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>397706715</td>\n",
       "      <td>FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>Trabajamos por la inclusi√≥n, el respeto y la i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>1176580744036196352</td>\n",
       "      <td>GaelAlejandro</td>\n",
       "      <td>¬°Estoy vivooo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>579360940</td>\n",
       "      <td>Juan Farre</td>\n",
       "      <td>#11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>326540841</td>\n",
       "      <td>YUNNYS L.</td>\n",
       "      <td>Ing. Industrial~UNEXPO.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4529 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author_id                 author_name  \\\n",
       "0     1423647858650136576   Subsecretar√≠a de Gobierno   \n",
       "1     1333482129716604928                Mauro Grande   \n",
       "2               492397405             Magdalena Ayala   \n",
       "3               132020962               Johanna Saenz   \n",
       "4              4106090319                         „ÄΩÔ∏è‚òï   \n",
       "...                   ...                         ...   \n",
       "4524            377788360      Eduardo D√≠atriü§çüíô‚ù§Ô∏è‚òÆÔ∏èüíõüíô   \n",
       "4525            397706715  FUVADIS INTERNACIONAL üè≥Ô∏è‚Äçüåà   \n",
       "4526  1176580744036196352               GaelAlejandro   \n",
       "4527            579360940                  Juan Farre   \n",
       "4528            326540841                   YUNNYS L.   \n",
       "\n",
       "                                     author_description  \n",
       "0           MUNICIPALIDAD  DE SAN MIGUEL - BUENOS AIRES  \n",
       "1     I'm stuck in a city but I belong in a field.\\n...  \n",
       "2        Hay que hacerse cargo de lo que uno dice, fin.  \n",
       "3     Mam√°. Polit√≥loga. Ms en Estudios Latinoamerica...  \n",
       "4              1997.\\n‚Ä¢     Club Atl√©tico River Plateüêì‚ù§  \n",
       "...                                                 ...  \n",
       "4524  Productor y asociado para espect√°culos mayores...  \n",
       "4525  Trabajamos por la inclusi√≥n, el respeto y la i...  \n",
       "4526                                     ¬°Estoy vivooo!  \n",
       "4527                                                #11  \n",
       "4528                            Ing. Industrial~UNEXPO.  \n",
       "\n",
       "[4529 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = df_tweets.drop_duplicates(subset=['author_id'], \n",
    "                                  keep='last').reset_index(drop=True)\n",
    "df_users = df_users.iloc[:, 1:]\n",
    "df_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-verse",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "La siguiente funci√≥n se encarga de pasar todo a min√∫sculas, eliminar acentos, URLs, emails, n√∫meros, caracteres que no sean letras y espacios en blancos duplicados. Esto nos ayudar√° a que al buscar los nombres o nacionalidades en los campos, se tenga m√°s posibilidades de encontrarlos, dado que no habr√° variaciones del tipo: \"NOE\", \"NoE\", \"Noe\", \"No√©\". Permitiendo que todas esas variaciones sean validas y encontradas con la cadena de texto \"noe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recognized-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_names(df_data, new_col, flg_remove_two_chars=True):\n",
    "\n",
    "    at_least_3_letter_reg = re.compile(r'\\b\\w{1,2}\\b')\n",
    "    at_least_3_letter_reg_capture = re.compile(r'\\b(\\w{2})\\b')\n",
    "\n",
    "    pre_text.initial_preprocessing(df_data, new_col,\n",
    "                                   flg_remove_emojis=True,\n",
    "                                   flg_lower=True)\n",
    "\n",
    "    pre_text.remove_urls(df_data, new_col)\n",
    "    pre_text.remove_emails(df_data, new_col)\n",
    "    pre_text.remove_urls(df_data, new_col)\n",
    "    pre_text.remove_numbers(df_data, new_col, \n",
    "                            replace_char=' ')\n",
    "\n",
    "    pre_text.remove_duplicated_chars(df_data, new_col)\n",
    "    pre_text.remove_non_alphanumeric(df_data, new_col)\n",
    "\n",
    "    pre_text.remove_single_letters(df_data, new_col)\n",
    "    \n",
    "    if(flg_remove_two_chars):\n",
    "        df_data[new_col] = df_data[new_col].str.replace(at_least_3_letter_reg, \n",
    "                                                        ' ', regex=True)\n",
    "\n",
    "    pre_text.remove_multiple_blank_spaces(df_data, new_col)\n",
    "    df_data[new_col] = df_data[new_col].str.strip()\n",
    "\n",
    "    valid_texts = ((~df_data[new_col].isna()) *\n",
    "                   (df_data[new_col] != '') *\n",
    "                   (~df_data[new_col].str.contains(r'^\\w$', regex=True)))\n",
    "    df_data = df_data[valid_texts]\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-alliance",
   "metadata": {},
   "source": [
    "Se le aplica la funci√≥n de limpieza a ambas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thermal-greeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1423647858650136576</td>\n",
       "      <td>subsecretaria gobierno</td>\n",
       "      <td>municipalidad de san miguel buenos aires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1333482129716604928</td>\n",
       "      <td>mauro grande</td>\n",
       "      <td>stuck in city but belong in field recibido en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>492397405</td>\n",
       "      <td>magdalena ayala</td>\n",
       "      <td>hay que hacerse cargo de lo que uno dice fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132020962</td>\n",
       "      <td>johana saenz</td>\n",
       "      <td>mama politologa ms en estudios latinoamericano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>809515814785347584</td>\n",
       "      <td>daniel vitolo</td>\n",
       "      <td>abogado docente consejero en uba derecho por f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>452492064</td>\n",
       "      <td>alfredo marquez</td>\n",
       "      <td>caminando su lado refugio de peludos rescatado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>377788360</td>\n",
       "      <td>eduardo diatri</td>\n",
       "      <td>productor asociado para espectaculos mayores d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>397706715</td>\n",
       "      <td>fuvadis internacional</td>\n",
       "      <td>trabajamos por la inclusion el respeto la inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>1176580744036196352</td>\n",
       "      <td>gaelalejandro</td>\n",
       "      <td>estoy vivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>326540841</td>\n",
       "      <td>yunys</td>\n",
       "      <td>ing industrial unexpo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author_id             author_name  \\\n",
       "0     1423647858650136576  subsecretaria gobierno   \n",
       "1     1333482129716604928            mauro grande   \n",
       "2               492397405         magdalena ayala   \n",
       "3               132020962            johana saenz   \n",
       "5      809515814785347584           daniel vitolo   \n",
       "...                   ...                     ...   \n",
       "4523            452492064         alfredo marquez   \n",
       "4524            377788360          eduardo diatri   \n",
       "4525            397706715   fuvadis internacional   \n",
       "4526  1176580744036196352           gaelalejandro   \n",
       "4528            326540841                   yunys   \n",
       "\n",
       "                                     author_description  \n",
       "0              municipalidad de san miguel buenos aires  \n",
       "1     stuck in city but belong in field recibido en ...  \n",
       "2          hay que hacerse cargo de lo que uno dice fin  \n",
       "3     mama politologa ms en estudios latinoamericano...  \n",
       "5     abogado docente consejero en uba derecho por f...  \n",
       "...                                                 ...  \n",
       "4523  caminando su lado refugio de peludos rescatado...  \n",
       "4524  productor asociado para espectaculos mayores d...  \n",
       "4525  trabajamos por la inclusion el respeto la inte...  \n",
       "4526                                         estoy vivo  \n",
       "4528                              ing industrial unexpo  \n",
       "\n",
       "[3832 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = preprocess_for_names(df_users.copy(), 'author_name')\n",
    "df_users = preprocess_for_names(df_users.copy(), 'author_description',\n",
    "                                flg_remove_two_chars=False)\n",
    "df_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-compound",
   "metadata": {},
   "source": [
    "## Look for the names on the twitter user name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_names = preprocess_for_names(df_data.copy(), 'author_name')\n",
    "\n",
    "# Extract composed and single names\n",
    "df_tmp2 = df_by_names['author_name'].str.extract(regex_names_double).dropna()\n",
    "\n",
    "df_tmp1 = df_by_names[~df_by_names.index.isin(df_tmp2.index)]['author_name']\n",
    "df_tmp1 = df_tmp1.str.extract(regex_names_single).dropna()\n",
    "\n",
    "# Map gender to the names\n",
    "df_by_names['extracted_name'] = pd.concat([df_tmp1, df_tmp2])[0]\n",
    "df_by_names['gender'] = df_by_names['extracted_name'].map(dict_names_gender)\n",
    "\n",
    "df_by_names = df_by_names.dropna()\n",
    "df_by_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-nightmare",
   "metadata": {},
   "source": [
    "## Look for the names on the twitter user description column\n",
    "\n",
    "\n",
    "TODO: To make a reliable search on the description field, first the official accounts from bussiness, organizations, etc. should be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_description = df_data[~df_data['author_id'].isin(df_by_names['author_id'])]\n",
    "\n",
    "# df_description = preprocess_for_names(df_description.copy(), 'author_description')\n",
    "\n",
    "# # Extract composed and single names\n",
    "# df_tmp2 = df_description['author_description'].str.extract(regex_names_double).dropna()\n",
    "\n",
    "# df_tmp1 = df_description[~df_description.index.isin(df_tmp2.index)]['author_description']\n",
    "# df_tmp1 = df_tmp1.str.extract(regex_names_single).dropna()\n",
    "\n",
    "# # Map gender to the names\n",
    "# df_description['extracted_name'] = pd.concat([df_tmp1, df_tmp2])[0]\n",
    "# df_description['gender'] = df_description['extracted_name'].map(dict_names_gender)\n",
    "\n",
    "# df_description = df_description.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-contrary",
   "metadata": {},
   "source": [
    "## Look for pronouns on the twitter user description\n",
    "\n",
    "TODO: Actually adjust the text preprocessing to avoid getting rid of pronouns patters, professional titles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regex_pronous = f\"\\\\b((?:{'|'.join(pronouns_dict.keys())}))\\\\b\"\n",
    "regex_pronous = re.compile(regex_pronous)\n",
    "regex_pronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pronouns = df_data[~df_data['author_id'].isin(df_by_names['author_id'])]\n",
    "\n",
    "df_pronouns = preprocess_for_names(df_pronouns.copy(), 'author_description',\n",
    "                                   flg_remove_two_chars=False)\n",
    "\n",
    "df_pronouns['extracted_pronoun'] = df_pronouns['author_description'].str.extract(regex_pronous).dropna()\n",
    "df_pronouns['gender'] = df_pronouns.dropna()['extracted_pronoun'].map(pronouns_dict)\n",
    "df_pronouns = df_pronouns.dropna()\n",
    "df_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-mission",
   "metadata": {},
   "source": [
    "## TODO: Look for profesional titles, like: Dr or Dra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-exclusion",
   "metadata": {},
   "source": [
    "## Merge the gender dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genders = pd.concat([df_by_names, df_pronouns])\n",
    "df_genders = df_genders.drop(columns=['extracted_name', 'extracted_pronoun'])\n",
    "\n",
    "df_genders = df_genders[['author_id', 'gender']]\n",
    "df_genders.columns = ['author_id', 'author_gender']\n",
    "df_genders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-forge",
   "metadata": {},
   "source": [
    "## Add gender column to the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw = df_tweets.merge(df_genders, on='author_id', how='left')\n",
    "df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw.to_parquet('TN.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BID",
   "language": "python",
   "name": "bid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
